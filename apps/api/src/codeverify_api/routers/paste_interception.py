"""Paste Interception API endpoints for real-time AI code verification.

This module provides fast endpoints optimized for the VS Code paste interception
feature, enabling instant verification of AI-generated code before it enters
the codebase.
"""

import hashlib
import time
from typing import Any

from fastapi import APIRouter, HTTPException, status
from pydantic import BaseModel, Field

import structlog

logger = structlog.get_logger()

router = APIRouter()


# =============================================================================
# Request/Response Models
# =============================================================================


class QuickAnalysisRequest(BaseModel):
    """Request for quick code analysis."""

    content: str = Field(..., min_length=1, max_length=100000)
    language: str = Field(default="python")
    mode: str = Field(default="quick", pattern="^(quick|standard|thorough)$")


class QuickAnalysisResponse(BaseModel):
    """Response from quick analysis."""

    findings: list[dict[str, Any]]
    analysis_time_ms: float
    mode: str


class QuickTrustScoreRequest(BaseModel):
    """Request for quick trust score calculation."""

    code: str = Field(..., min_length=1, max_length=100000)
    language: str = Field(default="python")


class QuickTrustScoreResponse(BaseModel):
    """Response with trust score."""

    score: float
    ai_probability: float
    risk_level: str
    is_ai_generated: bool
    detected_model: str
    factors: dict[str, float]
    analysis_time_ms: float


class PasteInterceptionRequest(BaseModel):
    """Combined request for paste interception analysis."""

    code: str = Field(..., min_length=1, max_length=100000)
    language: str = Field(default="python")


class PasteInterceptionResponse(BaseModel):
    """Combined response for paste interception."""

    id: str
    is_ai_generated: bool
    ai_confidence: float
    trust_score: float
    risk_level: str
    detected_model: str
    findings: list[dict[str, Any]]
    recommendations: list[str]
    analysis_time_ms: float


# =============================================================================
# Pattern-Based Quick Analysis
# =============================================================================


# Security patterns (critical/high severity)
SECURITY_PATTERNS = [
    (r"eval\s*\(", "security", "critical", "Unsafe eval() usage"),
    (r"exec\s*\(", "security", "critical", "Unsafe exec() usage"),
    (r"pickle\.loads?\(", "security", "critical", "Insecure deserialization"),
    (r"subprocess\..*shell\s*=\s*True", "security", "high", "Shell injection risk"),
    (r"os\.system\s*\(", "security", "high", "OS command injection risk"),
    (r"password\s*=\s*['\"][^'\"]+['\"]", "security", "critical", "Hardcoded password"),
    (r"api_key\s*=\s*['\"][^'\"]+['\"]", "security", "critical", "Hardcoded API key"),
    (r"secret\s*=\s*['\"][^'\"]+['\"]", "security", "critical", "Hardcoded secret"),
    (r"verify\s*=\s*False", "security", "high", "SSL verification disabled"),
    (r"__import__\s*\(", "security", "high", "Dynamic import (potential code injection)"),
]

# Logic patterns (medium/low severity)
LOGIC_PATTERNS = [
    (r"except\s*:\s*pass", "logic_error", "high", "Silent exception swallowing"),
    (r"except\s+Exception\s*:\s*pass", "logic_error", "high", "Broad exception silencing"),
    (r"raise\s+NotImplementedError", "logic_error", "medium", "Unimplemented stub"),
    (r"pass\s*#\s*(placeholder|implement|todo)", "logic_error", "medium", "Placeholder code"),
    (r"TODO:?\s*(implement|add|fix|complete)", "logic_error", "low", "TODO comment"),
    (r"FIXME", "logic_error", "medium", "FIXME comment"),
    (r"assert\s+False", "logic_error", "high", "Always-failing assertion"),
    (r"while\s+True\s*:", "logic_error", "medium", "Infinite loop (verify exit condition)"),
]

# AI detection patterns
AI_PATTERNS = [
    r"pass\s*#\s*(placeholder|implement)",
    r"# TODO:?\s*(implement|add|fix|complete)",
    r"# (This|The) (function|method|class) (does|will|should)",
    r"raise NotImplementedError",
    r'""".*\.\.\..*"""',
    r"# Example usage",
    r"if __name__ == ['\"]__main__['\"]:\s*#",
    r"# Generated by|Created with|Written by AI",
    r"Here's (a|an|the) (simple|basic|example)",
    r"Let me (explain|show|create)",
]

# Model-specific patterns
MODEL_PATTERNS = {
    "GitHub Copilot": [r"# Copilot", r"GitHub Copilot"],
    "ChatGPT": [r"```python", r"Here's (a|an|the)", r"Let me"],
    "Claude": [r"I'll (create|implement)", r"comprehensive", r"structured approach"],
}


def quick_pattern_analysis(code: str, language: str) -> list[dict[str, Any]]:
    """Perform fast pattern-based analysis."""
    import re

    findings = []
    finding_id = 0

    # Check security patterns
    for pattern, category, severity, title in SECURITY_PATTERNS:
        matches = list(re.finditer(pattern, code, re.IGNORECASE))
        for match in matches[:3]:  # Limit to 3 per pattern
            line_num = code[:match.start()].count('\n') + 1
            findings.append({
                "id": f"quick-{finding_id}",
                "category": category,
                "severity": severity,
                "title": title,
                "description": f"Pattern detected: {match.group()}",
                "file_path": "clipboard",
                "line_start": line_num,
                "line_end": line_num,
                "confidence": 0.85,
                "verification_type": "pattern",
            })
            finding_id += 1

    # Check logic patterns
    for pattern, category, severity, title in LOGIC_PATTERNS:
        matches = list(re.finditer(pattern, code, re.IGNORECASE))
        for match in matches[:3]:
            line_num = code[:match.start()].count('\n') + 1
            findings.append({
                "id": f"quick-{finding_id}",
                "category": category,
                "severity": severity,
                "title": title,
                "description": f"Pattern detected: {match.group()}",
                "file_path": "clipboard",
                "line_start": line_num,
                "line_end": line_num,
                "confidence": 0.75,
                "verification_type": "pattern",
            })
            finding_id += 1

    return findings


def quick_ai_detection(code: str) -> tuple[bool, float, str]:
    """Quickly detect if code is AI-generated."""
    import re

    ai_matches = 0
    total_patterns = len(AI_PATTERNS)

    for pattern in AI_PATTERNS:
        if re.search(pattern, code, re.IGNORECASE | re.MULTILINE):
            ai_matches += 1

    # Check comment consistency (AI tends to be very consistent)
    comment_lines = re.findall(r"^\s*#\s*.+$", code, re.MULTILINE)
    if len(comment_lines) > 3:
        comment_lengths = [len(c.strip()) for c in comment_lines]
        if comment_lengths:
            avg_len = sum(comment_lengths) / len(comment_lengths)
            variance = sum((l - avg_len) ** 2 for l in comment_lengths) / len(comment_lengths)
            if variance < 100:  # Low variance = likely AI
                ai_matches += 1
                total_patterns += 1

    confidence = ai_matches / max(total_patterns, 1)

    # Boost for multiple signals
    if ai_matches >= 3:
        confidence = min(confidence * 1.2, 0.99)

    is_ai = confidence > 0.4

    # Detect specific model
    detected_model = "unknown"
    for model, patterns in MODEL_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, code, re.IGNORECASE):
                detected_model = model
                break
        if detected_model != "unknown":
            break

    return is_ai, confidence, detected_model


def quick_trust_score(code: str, findings: list[dict[str, Any]], is_ai: bool, ai_confidence: float) -> float:
    """Calculate quick trust score."""
    import re

    score = 70.0  # Base score

    # Penalty for findings
    critical_count = sum(1 for f in findings if f["severity"] == "critical")
    high_count = sum(1 for f in findings if f["severity"] == "high")
    medium_count = sum(1 for f in findings if f["severity"] == "medium")

    score -= critical_count * 20
    score -= high_count * 10
    score -= medium_count * 5

    # Quality bonuses
    quality_patterns = [
        (r"def test_", 5),  # Has tests
        (r"assert\s+", 3),  # Has assertions
        (r"try:\s*\n.*\n\s*except\s+\w+", 5),  # Proper error handling
        (r":\s*(int|str|float|bool|list|dict|Optional|Union)", 5),  # Type hints
        (r'"""[\s\S]*?Args:', 5),  # Documented params
        (r"logging\.(debug|info|warning|error)", 3),  # Uses logging
    ]

    for pattern, bonus in quality_patterns:
        if re.search(pattern, code, re.IGNORECASE | re.MULTILINE):
            score += bonus

    # AI penalty
    if is_ai and ai_confidence > 0.7:
        score *= 0.85

    return max(0, min(100, score))


def determine_risk_level(trust_score: float, findings: list[dict[str, Any]]) -> str:
    """Determine risk level from trust score and findings."""
    has_critical = any(f["severity"] == "critical" for f in findings)

    if has_critical or trust_score < 40:
        return "critical"
    elif trust_score < 60:
        return "high"
    elif trust_score < 80:
        return "medium"
    return "low"


def generate_recommendations(
    is_ai: bool,
    trust_score: float,
    findings: list[dict[str, Any]],
) -> list[str]:
    """Generate recommendations based on analysis."""
    recommendations = []

    if is_ai:
        recommendations.append("AI-generated code detected. Manual review recommended.")

    has_security = any(f["category"] == "security" for f in findings)
    has_critical = any(f["severity"] == "critical" for f in findings)

    if has_critical:
        recommendations.append("Critical issues found. Fix before committing.")

    if has_security:
        recommendations.append("Security vulnerabilities detected. Security review required.")

    if trust_score < 60:
        recommendations.append("Low trust score. Consider running formal verification.")

    if not recommendations:
        recommendations.append("Code looks reasonable. Manual review still recommended.")

    return recommendations


# =============================================================================
# API Endpoints
# =============================================================================


@router.post("/quick", response_model=QuickAnalysisResponse)
async def quick_analysis(request: QuickAnalysisRequest) -> QuickAnalysisResponse:
    """Perform quick pattern-based analysis.

    Optimized for speed (<100ms target) for paste interception use case.
    """
    start_time = time.time()

    findings = quick_pattern_analysis(request.content, request.language)

    analysis_time_ms = (time.time() - start_time) * 1000

    logger.info(
        "Quick analysis completed",
        language=request.language,
        findings_count=len(findings),
        analysis_time_ms=analysis_time_ms,
    )

    return QuickAnalysisResponse(
        findings=findings,
        analysis_time_ms=round(analysis_time_ms, 2),
        mode=request.mode,
    )


@router.post("/trust-score/quick", response_model=QuickTrustScoreResponse)
async def quick_trust_score_endpoint(
    request: QuickTrustScoreRequest,
) -> QuickTrustScoreResponse:
    """Calculate quick trust score.

    Optimized for speed (<50ms target) for paste interception use case.
    """
    start_time = time.time()

    # AI detection
    is_ai, ai_confidence, detected_model = quick_ai_detection(request.code)

    # Quick analysis for trust score calculation
    findings = quick_pattern_analysis(request.code, request.language)

    # Calculate trust score
    trust_score = quick_trust_score(request.code, findings, is_ai, ai_confidence)

    # Determine risk level
    risk_level = determine_risk_level(trust_score, findings)

    analysis_time_ms = (time.time() - start_time) * 1000

    logger.info(
        "Quick trust score calculated",
        trust_score=trust_score,
        is_ai_generated=is_ai,
        ai_confidence=ai_confidence,
        analysis_time_ms=analysis_time_ms,
    )

    return QuickTrustScoreResponse(
        score=round(trust_score, 1),
        ai_probability=round(ai_confidence * 100, 1),
        risk_level=risk_level,
        is_ai_generated=is_ai,
        detected_model=detected_model,
        factors={
            "pattern_analysis": 0.7 if not findings else 0.3,
            "ai_detection": 1 - ai_confidence if not is_ai else ai_confidence,
        },
        analysis_time_ms=round(analysis_time_ms, 2),
    )


@router.post("/intercept", response_model=PasteInterceptionResponse)
async def paste_interception(
    request: PasteInterceptionRequest,
) -> PasteInterceptionResponse:
    """Combined endpoint for paste interception.

    Performs both AI detection, trust scoring, and quick analysis in one call.
    Target latency: <200ms.
    """
    start_time = time.time()

    # Generate unique ID
    code_hash = hashlib.sha256(request.code.encode()).hexdigest()[:12]
    interception_id = f"paste-{code_hash}-{int(time.time())}"

    # AI detection
    is_ai, ai_confidence, detected_model = quick_ai_detection(request.code)

    # Quick analysis
    findings = quick_pattern_analysis(request.code, request.language)

    # Trust score
    trust_score = quick_trust_score(request.code, findings, is_ai, ai_confidence)

    # Risk level
    risk_level = determine_risk_level(trust_score, findings)

    # Recommendations
    recommendations = generate_recommendations(is_ai, trust_score, findings)

    analysis_time_ms = (time.time() - start_time) * 1000

    logger.info(
        "Paste interception analysis completed",
        interception_id=interception_id,
        is_ai_generated=is_ai,
        trust_score=trust_score,
        risk_level=risk_level,
        findings_count=len(findings),
        analysis_time_ms=analysis_time_ms,
    )

    return PasteInterceptionResponse(
        id=interception_id,
        is_ai_generated=is_ai,
        ai_confidence=round(ai_confidence, 4),
        trust_score=round(trust_score, 1),
        risk_level=risk_level,
        detected_model=detected_model,
        findings=findings,
        recommendations=recommendations,
        analysis_time_ms=round(analysis_time_ms, 2),
    )
