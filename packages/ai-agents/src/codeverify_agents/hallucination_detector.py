"""AI Hallucination Detector - Detect when AI coding tools hallucinate non-existent APIs.

This module analyzes code generated by AI tools (Copilot, ChatGPT, etc.) to identify
references to APIs, modules, functions, or signatures that do not actually exist.
AI models frequently "hallucinate" plausible-sounding but fictional APIs, leading
to import errors, runtime failures, and subtle bugs.

Features:
- Extract imports from Python, TypeScript/JS, Go, and Java source code
- Validate imports against known package registries (offline)
- Detect commonly hallucinated API patterns
- Report confidence-scored findings with suggested corrections
- Support version-aware validation for deprecated or moved APIs
"""

from __future__ import annotations

import re
import time
from dataclasses import dataclass
from enum import Enum
from typing import Any

import structlog

from codeverify_agents.base import AgentConfig, AgentResult, BaseAgent

logger = structlog.get_logger()


# =============================================================================
# Enums and Data Classes
# =============================================================================


class HallucinationType(str, Enum):
    """Types of API hallucinations produced by AI coding tools."""

    NONEXISTENT_MODULE = "nonexistent_module"
    NONEXISTENT_FUNCTION = "nonexistent_function"
    WRONG_SIGNATURE = "wrong_signature"
    DEPRECATED_API = "deprecated_api"
    VERSION_MISMATCH = "version_mismatch"


@dataclass
class HallucinationFinding:
    """A single detected hallucination in AI-generated code.

    Attributes:
        type: The category of hallucination detected.
        import_path: The full import path referenced in the code.
        symbol: The specific symbol (function, class, constant) that was hallucinated.
        line_number: The source line where the hallucination was found.
        confidence: Confidence score from 0.0 (uncertain) to 1.0 (definite).
        suggestion: What the author probably intended to write.
        evidence: Human-readable explanation of why this is considered a hallucination.
    """

    type: HallucinationType
    import_path: str
    symbol: str
    line_number: int
    confidence: float
    suggestion: str
    evidence: str

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "type": self.type.value,
            "import_path": self.import_path,
            "symbol": self.symbol,
            "line_number": self.line_number,
            "confidence": self.confidence,
            "suggestion": self.suggestion,
            "evidence": self.evidence,
        }


@dataclass
class ImportInfo:
    """Parsed information about a single import statement.

    Attributes:
        module: The module or package being imported from.
        symbol: The specific symbol imported (empty string for whole-module imports).
        alias: The alias assigned via 'as' keyword, if any.
        line_number: The source line of the import statement.
        is_from_import: Whether this uses 'from X import Y' style (Python).
    """

    module: str
    symbol: str
    alias: str
    line_number: int
    is_from_import: bool

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "module": self.module,
            "symbol": self.symbol,
            "alias": self.alias,
            "line_number": self.line_number,
            "is_from_import": self.is_from_import,
        }


@dataclass
class ValidationResult:
    """Result of validating a single import against known packages.

    Attributes:
        valid: Whether the import is considered valid.
        confidence: Confidence in the validation result (0.0 to 1.0).
        reason: Human-readable explanation of the validation outcome.
        suggestion: Suggested correction if the import is invalid.
    """

    valid: bool
    confidence: float
    reason: str
    suggestion: str

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "valid": self.valid,
            "confidence": self.confidence,
            "reason": self.reason,
            "suggestion": self.suggestion,
        }


# =============================================================================
# Import Extraction
# =============================================================================


class ImportExtractor:
    """Extracts import statements from source code across multiple languages.

    Supports Python, TypeScript/JavaScript, Go, and Java import syntax.
    """

    def extract_imports(self, code: str, language: str) -> list[ImportInfo]:
        """Extract all import statements from the given source code.

        Args:
            code: The source code to analyse.
            language: Programming language identifier (python, typescript, javascript,
                      go, java).

        Returns:
            A list of ImportInfo objects describing every import found.
        """
        language = language.lower()
        if language in ("python", "py"):
            return self._extract_python_imports(code)
        elif language in ("typescript", "ts", "javascript", "js"):
            return self._extract_ts_js_imports(code)
        elif language == "go":
            return self._extract_go_imports(code)
        elif language == "java":
            return self._extract_java_imports(code)
        return []

    # -- Python ---------------------------------------------------------------

    def _extract_python_imports(self, code: str) -> list[ImportInfo]:
        """Extract Python import and from...import statements."""
        imports: list[ImportInfo] = []
        for line_number, line in enumerate(code.splitlines(), start=1):
            stripped = line.strip()

            # from X import Y, Z as A
            from_match = re.match(
                r"^from\s+([\w.]+)\s+import\s+(.+)$", stripped
            )
            if from_match:
                module = from_match.group(1)
                symbols_part = from_match.group(2)
                for sym_chunk in symbols_part.split(","):
                    sym_chunk = sym_chunk.strip()
                    if not sym_chunk:
                        continue
                    parts = re.split(r"\s+as\s+", sym_chunk, maxsplit=1)
                    symbol = parts[0].strip()
                    alias = parts[1].strip() if len(parts) > 1 else ""
                    imports.append(ImportInfo(
                        module=module,
                        symbol=symbol,
                        alias=alias,
                        line_number=line_number,
                        is_from_import=True,
                    ))
                continue

            # import X, Y as A
            import_match = re.match(r"^import\s+(.+)$", stripped)
            if import_match:
                modules_part = import_match.group(1)
                for mod_chunk in modules_part.split(","):
                    mod_chunk = mod_chunk.strip()
                    if not mod_chunk:
                        continue
                    parts = re.split(r"\s+as\s+", mod_chunk, maxsplit=1)
                    module = parts[0].strip()
                    alias = parts[1].strip() if len(parts) > 1 else ""
                    imports.append(ImportInfo(
                        module=module,
                        symbol="",
                        alias=alias,
                        line_number=line_number,
                        is_from_import=False,
                    ))

        return imports

    # -- TypeScript / JavaScript ----------------------------------------------

    def _extract_ts_js_imports(self, code: str) -> list[ImportInfo]:
        """Extract TypeScript and JavaScript import statements."""
        imports: list[ImportInfo] = []
        for line_number, line in enumerate(code.splitlines(), start=1):
            stripped = line.strip()

            # import { A, B as C } from 'module'
            named_match = re.match(
                r"""^import\s*\{([^}]+)\}\s*from\s*['"]([^'"]+)['"]""",
                stripped,
            )
            if named_match:
                symbols_part = named_match.group(1)
                module = named_match.group(2)
                for sym_chunk in symbols_part.split(","):
                    sym_chunk = sym_chunk.strip()
                    if not sym_chunk:
                        continue
                    parts = re.split(r"\s+as\s+", sym_chunk, maxsplit=1)
                    symbol = parts[0].strip()
                    alias = parts[1].strip() if len(parts) > 1 else ""
                    imports.append(ImportInfo(
                        module=module,
                        symbol=symbol,
                        alias=alias,
                        line_number=line_number,
                        is_from_import=True,
                    ))
                continue

            # import DefaultExport from 'module'
            default_match = re.match(
                r"""^import\s+(\w+)\s+from\s*['"]([^'"]+)['"]""",
                stripped,
            )
            if default_match:
                symbol = default_match.group(1)
                module = default_match.group(2)
                imports.append(ImportInfo(
                    module=module,
                    symbol=symbol,
                    alias="",
                    line_number=line_number,
                    is_from_import=True,
                ))
                continue

            # import * as Alias from 'module'
            star_match = re.match(
                r"""^import\s+\*\s+as\s+(\w+)\s+from\s*['"]([^'"]+)['"]""",
                stripped,
            )
            if star_match:
                alias = star_match.group(1)
                module = star_match.group(2)
                imports.append(ImportInfo(
                    module=module,
                    symbol="*",
                    alias=alias,
                    line_number=line_number,
                    is_from_import=True,
                ))
                continue

            # const/require pattern: const x = require('module')
            require_match = re.match(
                r"""^(?:const|let|var)\s+(\w+)\s*=\s*require\s*\(\s*['"]([^'"]+)['"]\s*\)""",
                stripped,
            )
            if require_match:
                alias = require_match.group(1)
                module = require_match.group(2)
                imports.append(ImportInfo(
                    module=module,
                    symbol="",
                    alias=alias,
                    line_number=line_number,
                    is_from_import=False,
                ))

        return imports

    # -- Go -------------------------------------------------------------------

    def _extract_go_imports(self, code: str) -> list[ImportInfo]:
        """Extract Go import statements (single and grouped)."""
        imports: list[ImportInfo] = []

        # Single import: import "fmt"  or  import alias "pkg"
        for line_number, line in enumerate(code.splitlines(), start=1):
            single_match = re.match(
                r"""^\s*import\s+(?:(\w+)\s+)?["']([^"']+)["']""", line
            )
            if single_match:
                alias = single_match.group(1) or ""
                module = single_match.group(2)
                imports.append(ImportInfo(
                    module=module,
                    symbol="",
                    alias=alias,
                    line_number=line_number,
                    is_from_import=False,
                ))

        # Grouped import block: import ( ... )
        group_pattern = re.compile(
            r"import\s*\((.*?)\)", re.DOTALL
        )
        for group_match in group_pattern.finditer(code):
            block = group_match.group(1)
            block_start = code[: group_match.start()].count("\n") + 1
            for offset, pkg_line in enumerate(block.splitlines()):
                pkg_line = pkg_line.strip()
                if not pkg_line:
                    continue
                pkg_match = re.match(
                    r"""(?:(\w+)\s+)?["']([^"']+)["']""", pkg_line
                )
                if pkg_match:
                    alias = pkg_match.group(1) or ""
                    module = pkg_match.group(2)
                    imports.append(ImportInfo(
                        module=module,
                        symbol="",
                        alias=alias,
                        line_number=block_start + offset + 1,
                        is_from_import=False,
                    ))

        return imports

    # -- Java -----------------------------------------------------------------

    def _extract_java_imports(self, code: str) -> list[ImportInfo]:
        """Extract Java import statements."""
        imports: list[ImportInfo] = []
        for line_number, line in enumerate(code.splitlines(), start=1):
            match = re.match(
                r"^\s*import\s+(?:static\s+)?([\w.]+(?:\.\*)?)\s*;", line
            )
            if match:
                full_path = match.group(1)
                parts = full_path.rsplit(".", 1)
                if len(parts) == 2:
                    module, symbol = parts
                else:
                    module = parts[0]
                    symbol = ""
                imports.append(ImportInfo(
                    module=module,
                    symbol=symbol,
                    alias="",
                    line_number=line_number,
                    is_from_import=True,
                ))

        return imports


# =============================================================================
# Package Validation
# =============================================================================


class PackageValidator:
    """Validates imports against a catalogue of known packages and their exports.

    Uses an offline dictionary of common standard-library and third-party
    packages so that basic validation can run without network access.
    """

    # Python standard library modules and selected exports
    KNOWN_PACKAGES: dict[str, dict[str, list[str]]] = {
        "python": {
            "os": ["getcwd", "listdir", "makedirs", "remove", "rename", "environ",
                    "path", "getenv", "walk", "sep", "linesep", "cpu_count"],
            "os.path": ["join", "exists", "isfile", "isdir", "basename", "dirname",
                        "abspath", "splitext", "expanduser", "relpath", "getsize"],
            "sys": ["argv", "exit", "path", "stdin", "stdout", "stderr",
                    "version", "platform", "modules", "executable", "maxsize"],
            "json": ["loads", "dumps", "load", "dump", "JSONDecodeError",
                     "JSONEncoder", "JSONDecoder"],
            "pathlib": ["Path", "PurePath", "PosixPath", "WindowsPath",
                        "PurePosixPath", "PureWindowsPath"],
            "typing": ["Any", "Dict", "List", "Optional", "Tuple", "Union",
                       "Set", "Callable", "TypeVar", "Generic", "ClassVar",
                       "Final", "Literal", "TypedDict", "Protocol",
                       "NamedTuple", "Sequence", "Mapping", "Iterator"],
            "collections": ["defaultdict", "OrderedDict", "Counter", "deque",
                            "namedtuple", "ChainMap", "UserDict", "UserList"],
            "itertools": ["chain", "combinations", "permutations", "product",
                          "cycle", "repeat", "islice", "groupby", "starmap",
                          "zip_longest", "count", "accumulate", "filterfalse"],
            "functools": ["reduce", "partial", "lru_cache", "wraps",
                          "total_ordering", "cached_property", "singledispatch",
                          "cache", "partialmethod"],
            "dataclasses": ["dataclass", "field", "asdict", "astuple",
                            "fields", "is_dataclass", "make_dataclass",
                            "replace", "InitVar", "Field", "FrozenInstanceError"],
            "asyncio": ["run", "gather", "create_task", "sleep", "wait",
                        "Event", "Lock", "Queue", "Semaphore", "Task",
                        "get_event_loop", "new_event_loop", "ensure_future",
                        "wait_for", "shield", "StreamReader", "StreamWriter"],
            "re": ["compile", "match", "search", "findall", "finditer", "sub",
                   "subn", "split", "fullmatch", "Pattern", "Match",
                   "IGNORECASE", "MULTILINE", "DOTALL", "VERBOSE"],
            "datetime": ["datetime", "date", "time", "timedelta", "timezone",
                         "tzinfo", "MINYEAR", "MAXYEAR"],
            "math": ["sqrt", "ceil", "floor", "log", "log2", "log10", "pow",
                     "sin", "cos", "tan", "pi", "e", "inf", "nan", "isnan",
                     "isinf", "factorial", "gcd", "comb", "perm"],
            "hashlib": ["sha256", "sha512", "md5", "sha1", "sha384",
                        "blake2b", "blake2s", "new", "algorithms_available",
                        "algorithms_guaranteed"],
            "uuid": ["uuid4", "uuid1", "uuid3", "uuid5", "UUID", "NAMESPACE_DNS",
                     "NAMESPACE_URL", "NAMESPACE_OID", "NAMESPACE_X500"],
            "http": ["HTTPStatus", "server", "client", "cookies", "cookiejar"],
            "http.server": ["HTTPServer", "BaseHTTPRequestHandler",
                            "SimpleHTTPRequestHandler"],
            "urllib": ["request", "parse", "error", "robotparser"],
            "urllib.parse": ["urlparse", "urljoin", "urlencode", "quote",
                             "unquote", "parse_qs", "parse_qsl", "urlsplit"],
        },
        "node": {
            "fs": ["readFile", "writeFile", "readFileSync", "writeFileSync",
                   "existsSync", "mkdirSync", "readdirSync", "statSync",
                   "unlinkSync", "renameSync", "createReadStream",
                   "createWriteStream", "promises", "watch", "access"],
            "path": ["join", "resolve", "basename", "dirname", "extname",
                     "normalize", "parse", "format", "isAbsolute", "relative",
                     "sep", "delimiter", "posix", "win32"],
            "http": ["createServer", "request", "get", "Server",
                     "IncomingMessage", "ServerResponse", "STATUS_CODES",
                     "METHODS", "Agent", "globalAgent"],
            "crypto": ["createHash", "createHmac", "createCipheriv",
                       "createDecipheriv", "randomBytes", "randomUUID",
                       "pbkdf2", "scrypt", "generateKeyPair", "sign", "verify"],
            "stream": ["Readable", "Writable", "Transform", "Duplex",
                       "PassThrough", "pipeline", "finished"],
            "events": ["EventEmitter", "on", "once", "getEventListeners",
                       "listenerCount"],
            "util": ["promisify", "inspect", "format", "types", "TextDecoder",
                     "TextEncoder", "deprecate", "inherits", "callbackify"],
            "child_process": ["exec", "execSync", "spawn", "spawnSync",
                              "fork", "execFile", "execFileSync"],
            "os": ["hostname", "platform", "arch", "cpus", "totalmem",
                   "freemem", "homedir", "tmpdir", "type", "release",
                   "networkInterfaces", "userInfo", "EOL"],
            "buffer": ["Buffer", "Blob", "SlowBuffer", "transcode",
                       "isEncoding", "isBuffer", "kMaxLength"],
        },
    }

    def validate_import(
        self, module: str, symbol: str, language: str,
    ) -> ValidationResult:
        """Validate whether an import is known to exist.

        Args:
            module: The module/package being imported.
            symbol: The specific symbol imported (may be empty).
            language: The programming language (python, typescript, javascript, go, java).

        Returns:
            A ValidationResult indicating validity and confidence.
        """
        lang_key = self._language_key(language)
        known = self.KNOWN_PACKAGES.get(lang_key, {})

        # Module not in our catalogue at all -- we cannot say it is wrong
        if module not in known:
            return ValidationResult(
                valid=True,
                confidence=0.2,
                reason=f"Module '{module}' is not in the offline catalogue; cannot verify.",
                suggestion="",
            )

        # Module exists; if no specific symbol requested, it is valid
        if not symbol:
            return ValidationResult(
                valid=True,
                confidence=0.9,
                reason=f"Module '{module}' is a known {lang_key} package.",
                suggestion="",
            )

        exports = known[module]
        if symbol in exports:
            return ValidationResult(
                valid=True,
                confidence=0.95,
                reason=f"'{symbol}' is a known export of '{module}'.",
                suggestion="",
            )

        # Symbol not found -- look for close matches
        suggestion = self._find_closest(symbol, exports)
        return ValidationResult(
            valid=False,
            confidence=0.8,
            reason=f"'{symbol}' is not a known export of '{module}'.",
            suggestion=suggestion,
        )

    # -- Helpers --------------------------------------------------------------

    @staticmethod
    def _language_key(language: str) -> str:
        """Normalise a language name to an internal key."""
        language = language.lower()
        if language in ("python", "py"):
            return "python"
        if language in ("typescript", "ts", "javascript", "js", "node"):
            return "node"
        return language

    @staticmethod
    def _find_closest(target: str, candidates: list[str]) -> str:
        """Return the candidate most similar to *target* using basic edit distance."""
        if not candidates:
            return ""
        target_lower = target.lower()
        scored = []
        for c in candidates:
            c_lower = c.lower()
            # Simple similarity: ratio of common characters in order
            common = 0
            j = 0
            for ch in target_lower:
                idx = c_lower.find(ch, j)
                if idx != -1:
                    common += 1
                    j = idx + 1
            score = common / max(len(target_lower), len(c_lower))
            scored.append((score, c))
        scored.sort(key=lambda x: x[0], reverse=True)
        return scored[0][1] if scored else ""


# =============================================================================
# Common Hallucinations Database
# =============================================================================


class CommonHallucinations:
    """Database of frequently hallucinated APIs produced by AI coding tools.

    Each entry maps a hallucinated import path to metadata about the correct
    alternative, the typical confusion, and the confidence that seeing this
    import is a hallucination rather than a real (niche) API.
    """

    KNOWN_HALLUCINATIONS: dict[str, dict[str, str]] = {
        # -- Python standard library confusions --------------------------------
        "os.path.joinpath": {
            "suggestion": "Use os.path.join() or pathlib.Path.joinpath()",
            "reason": "os.path.joinpath does not exist; joinpath is a method on pathlib.Path.",
            "confidence": "0.95",
        },
        "json.loads_file": {
            "suggestion": "Use json.load(fp) to read from a file object",
            "reason": "json.loads_file does not exist. Use json.load() for files or json.loads() for strings.",
            "confidence": "0.95",
        },
        "json.dump_to_file": {
            "suggestion": "Use json.dump(obj, fp) to write to a file object",
            "reason": "json.dump_to_file does not exist. Use json.dump() with a file handle.",
            "confidence": "0.95",
        },
        "collections.DefaultDict": {
            "suggestion": "Use collections.defaultdict (lowercase)",
            "reason": "The class is collections.defaultdict, not collections.DefaultDict.",
            "confidence": "0.9",
        },
        "collections.OrderedDefaultDict": {
            "suggestion": "Use collections.defaultdict or collections.OrderedDict separately",
            "reason": "OrderedDefaultDict does not exist in the standard library.",
            "confidence": "0.95",
        },
        # -- Third-party Python confusions -------------------------------------
        "pandas.read_sql_table": {
            "suggestion": "Use pandas.read_sql() or pandas.read_sql_query()",
            "reason": "pandas.read_sql_table exists but is often confused with read_sql. Verify the intended function.",
            "confidence": "0.6",
        },
        "pandas.to_datetime_string": {
            "suggestion": "Use pandas.Timestamp.strftime() or Series.dt.strftime()",
            "reason": "pandas.to_datetime_string does not exist.",
            "confidence": "0.9",
        },
        "requests.get_json": {
            "suggestion": "Use response = requests.get(url); data = response.json()",
            "reason": "requests.get_json does not exist. Call .json() on the Response object.",
            "confidence": "0.95",
        },
        "requests.post_json": {
            "suggestion": "Use requests.post(url, json=data)",
            "reason": "requests.post_json does not exist. Pass json= kwarg to requests.post().",
            "confidence": "0.95",
        },
        "numpy.array_chunk": {
            "suggestion": "Use numpy.array_split()",
            "reason": "numpy.array_chunk does not exist; use numpy.array_split instead.",
            "confidence": "0.95",
        },
        "numpy.flatten": {
            "suggestion": "Use ndarray.flatten() or numpy.ravel()",
            "reason": "numpy.flatten is not a top-level function; call .flatten() on an array.",
            "confidence": "0.85",
        },
        # -- Version-specific issues -------------------------------------------
        "typing.TypedDict": {
            "suggestion": "Available in Python 3.8+; use typing_extensions.TypedDict for earlier versions",
            "reason": "typing.TypedDict was added in Python 3.8. Code targeting older versions should use typing_extensions.",
            "confidence": "0.5",
        },
        "asyncio.TaskGroup": {
            "suggestion": "Available in Python 3.11+; use anyio or a backport for earlier versions",
            "reason": "asyncio.TaskGroup was added in Python 3.11.",
            "confidence": "0.5",
        },
        "dataclasses.KW_ONLY": {
            "suggestion": "Available in Python 3.10+",
            "reason": "dataclasses.KW_ONLY was added in Python 3.10.",
            "confidence": "0.5",
        },
        # -- Node.js confusions ------------------------------------------------
        "fs.readJSON": {
            "suggestion": "Use fs.readFileSync() then JSON.parse(), or use fs-extra's readJsonSync",
            "reason": "fs.readJSON does not exist in Node core; it comes from fs-extra.",
            "confidence": "0.9",
        },
        "path.joinPath": {
            "suggestion": "Use path.join()",
            "reason": "path.joinPath does not exist; use path.join().",
            "confidence": "0.95",
        },
        "http.createClient": {
            "suggestion": "Use http.request() or a library like axios/node-fetch",
            "reason": "http.createClient was removed long ago. Use http.request() instead.",
            "confidence": "0.9",
        },
        "crypto.generateHash": {
            "suggestion": "Use crypto.createHash(algorithm).update(data).digest(encoding)",
            "reason": "crypto.generateHash does not exist; use crypto.createHash().",
            "confidence": "0.95",
        },
        "util.isString": {
            "suggestion": "Use typeof value === 'string'",
            "reason": "util.isString was deprecated and removed. Use typeof checks.",
            "confidence": "0.9",
        },
    }

    def check(self, import_path: str) -> dict[str, str] | None:
        """Check if an import path matches a known hallucination.

        Args:
            import_path: A dotted import path such as 'requests.get_json'.

        Returns:
            A dict with 'suggestion', 'reason', and 'confidence' if the path
            matches a known hallucination, otherwise None.
        """
        return self.KNOWN_HALLUCINATIONS.get(import_path)

    def check_partial(self, module: str, symbol: str) -> dict[str, str] | None:
        """Check module + symbol combination against known hallucinations.

        Constructs candidate keys like 'module.symbol' and looks them up.
        """
        if symbol:
            key = f"{module}.{symbol}"
            result = self.KNOWN_HALLUCINATIONS.get(key)
            if result:
                return result
        return None


# =============================================================================
# Hallucination Detector Agent
# =============================================================================


class HallucinationDetectorAgent(BaseAgent):
    """Agent that detects hallucinated APIs in AI-generated code.

    Combines static import extraction, offline package validation, and a
    database of commonly hallucinated patterns to identify non-existent
    APIs that AI coding tools frequently produce.

    Example usage::

        agent = HallucinationDetectorAgent()
        result = await agent.analyze(
            code='import json\\ndata = json.loads_file("config.json")',
            context={"language": "python"},
        )
        print(result.data["findings"])
    """

    def __init__(self, config: AgentConfig | None = None) -> None:
        """Initialize the hallucination detector with its sub-components."""
        super().__init__(config)
        self._extractor = ImportExtractor()
        self._validator = PackageValidator()
        self._hallucinations_db = CommonHallucinations()

    async def analyze(self, code: str, context: dict[str, Any]) -> AgentResult:
        """Analyze code for hallucinated API references.

        Args:
            code: The source code to analyze.
            context: Additional context. Expected keys:
                - language (str): Programming language (default 'python').
                - file_path (str): Path of the source file (informational).

        Returns:
            AgentResult with ``data`` containing:
                - findings: list of serialized HallucinationFinding dicts
                - total_imports: number of imports extracted
                - hallucination_count: number of hallucinations detected
                - risk_score: 0-100 overall risk score
        """
        start_time = time.time()
        language = context.get("language", "python")

        try:
            findings = self._extract_and_validate(code, language)

            risk_score = self._compute_risk_score(findings)

            elapsed_ms = (time.time() - start_time) * 1000

            logger.info(
                "Hallucination detection completed",
                language=language,
                findings=len(findings),
                risk_score=risk_score,
                latency_ms=elapsed_ms,
            )

            return AgentResult(
                success=True,
                data={
                    "findings": [f.to_dict() for f in findings],
                    "total_imports": len(
                        self._extractor.extract_imports(code, language)
                    ),
                    "hallucination_count": len(findings),
                    "risk_score": risk_score,
                },
                latency_ms=elapsed_ms,
            )

        except Exception as e:
            logger.error("Hallucination detection failed", error=str(e))
            return AgentResult(
                success=False,
                error=str(e),
                latency_ms=(time.time() - start_time) * 1000,
            )

    # -- Core detection pipeline ----------------------------------------------

    def _extract_and_validate(
        self, code: str, language: str,
    ) -> list[HallucinationFinding]:
        """Extract imports from code and validate each against known packages.

        Args:
            code: Source code to analyse.
            language: Programming language identifier.

        Returns:
            A list of HallucinationFinding for every suspicious import.
        """
        imports = self._extractor.extract_imports(code, language)
        findings: list[HallucinationFinding] = []

        # Phase 1: Check against common hallucination database
        hallucination_findings = self._check_common_hallucinations(imports)
        # Track which imports already have findings to avoid duplicates
        reported_keys: set[str] = set()
        for hf in hallucination_findings:
            reported_keys.add(f"{hf.import_path}:{hf.symbol}")
        findings.extend(hallucination_findings)

        # Phase 2: Validate remaining imports against known packages
        for imp in imports:
            key = f"{imp.module}.{imp.symbol}" if imp.symbol else imp.module
            report_key = f"{key}:{imp.symbol}"
            if report_key in reported_keys:
                continue

            result = self._validator.validate_import(
                imp.module, imp.symbol, language,
            )
            if not result.valid:
                h_type = (
                    HallucinationType.NONEXISTENT_FUNCTION
                    if imp.symbol
                    else HallucinationType.NONEXISTENT_MODULE
                )
                findings.append(HallucinationFinding(
                    type=h_type,
                    import_path=imp.module,
                    symbol=imp.symbol,
                    line_number=imp.line_number,
                    confidence=result.confidence,
                    suggestion=result.suggestion,
                    evidence=result.reason,
                ))

        return findings

    def _check_common_hallucinations(
        self, imports: list[ImportInfo],
    ) -> list[HallucinationFinding]:
        """Check extracted imports against the common hallucinations database.

        Args:
            imports: List of parsed ImportInfo objects.

        Returns:
            HallucinationFinding entries for any matches found.
        """
        findings: list[HallucinationFinding] = []

        for imp in imports:
            result = self._hallucinations_db.check_partial(
                imp.module, imp.symbol,
            )
            if result is None:
                continue

            confidence = float(result.get("confidence", "0.8"))

            # Determine hallucination type from the result reason
            h_type = self._classify_hallucination(result.get("reason", ""))

            import_path = (
                f"{imp.module}.{imp.symbol}" if imp.symbol else imp.module
            )

            findings.append(HallucinationFinding(
                type=h_type,
                import_path=import_path,
                symbol=imp.symbol or imp.module.rsplit(".", 1)[-1],
                line_number=imp.line_number,
                confidence=confidence,
                suggestion=result.get("suggestion", ""),
                evidence=result.get("reason", ""),
            ))

        return findings

    # -- Helpers --------------------------------------------------------------

    @staticmethod
    def _classify_hallucination(reason: str) -> HallucinationType:
        """Infer the HallucinationType from a textual reason string."""
        reason_lower = reason.lower()
        if "deprecated" in reason_lower or "removed" in reason_lower:
            return HallucinationType.DEPRECATED_API
        if "version" in reason_lower or "added in" in reason_lower:
            return HallucinationType.VERSION_MISMATCH
        if "does not exist" in reason_lower:
            return HallucinationType.NONEXISTENT_FUNCTION
        if "not a known export" in reason_lower:
            return HallucinationType.NONEXISTENT_FUNCTION
        return HallucinationType.NONEXISTENT_FUNCTION

    @staticmethod
    def _compute_risk_score(findings: list[HallucinationFinding]) -> float:
        """Compute a 0-100 risk score based on findings.

        The score increases with the number and confidence of findings.
        A single high-confidence hallucination is already a significant risk
        since it will cause a runtime ImportError or AttributeError.
        """
        if not findings:
            return 0.0

        weighted_sum = sum(f.confidence for f in findings)
        # Each high-confidence finding contributes ~20 points, capped at 100
        score = min(100.0, weighted_sum * 20.0)
        return round(score, 1)
